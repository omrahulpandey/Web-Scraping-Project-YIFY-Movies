{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Movie Details from YIFY Movies\n",
    "\n",
    "![banner-image](https://i.imgur.com/V1XCM6l.jpg)\n",
    "\n",
    "\n",
    "#### Web Scraping \n",
    "- Web Scraping is a way to extract information (or simply data) from webpages using various tools and techniques. You can read more about web scraping [here](https://en.wikipedia.org/wiki/Web_scraping). \n",
    "#### Why Web Scraping?\n",
    "- There are many websites that contain certain types of data which may prove to be invaluable in-terms of day-to-day needs, academic-research, industry-use, bussiness, etc\n",
    "\n",
    "- [Stock-rates](https://www.moneycontrol.com/),  [product detials](https://www.amazon.in/Chitralekha-Bhagwaticharan-Verma/dp/8126715855/ref=tmm_pap_swatch_0?_encoding=UTF8&qid=&sr=),  [sports stats](https://www.skysports.com/football/tables),  [weather forecasts](https://www.accuweather.com/en/in/ghaziabad/206683/september-weather/206683),  [movie-ratings](https://yts.rs/movie/the-protege-2021)  and what not. \n",
    "\n",
    "#### YIFY Movies:\n",
    "-  [YIFY Movies](https://yts.rs/) , a website that offers free to download movie torrent links, having an enormous database for movies and documentaries.\n",
    "- We would like to extract movie details (like title, year, genre, rating, movie_link, synopsis and no. of times downloaded) for our project.\n",
    "\n",
    "\n",
    "#### Tools\n",
    "- [Pyhton 3.7](https://www.python.org/downloads/) and above along with [Juypter Notebooks](https://jupyter.org/install.html).\n",
    "- [Pandas library](https://pandas.pydata.org/docs/) to create dataframe as well as saving the output to [.csv](https://en.wikipedia.org/wiki/Comma-separated_values) file.\n",
    "- [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) for parsing the html_page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outline:\n",
    "Here's an outline of the steps we'll follow:\n",
    "\n",
    "1. Download the webpage using the `requests`\n",
    "2. Parse the HTML source code using beautiful soup\n",
    "3. Searching 'tags' containing data for movie title, year, genre, rating, movie-url, synopsis and number of times downloaded.\n",
    "4. Scrap from multiple pages (in our case 20 pages) and compile the information into Python lists and dictionaries.\n",
    "5. Save the extracted information to a CSV file.\n",
    "\n",
    "By the time we finsih our project, we would have a CSV file created in the following format:\n",
    "\n",
    "````````\n",
    "Movie,Year,Genre,Ratings,Url,Synopsis,Downloaded\n",
    "Whale Hunting,1984,Drama,6.5 / 10,https://yts.rs/movie/whale-hunting-1984,\" A disillusioned student meets a eccentric beggar and a mute prostitute he falls in love with. Together, without money, they cross South Korea to help the girl go home. \",\" Downloaded 101 times  Sep 27, 2021 at 09:08 PM\n",
    "........\n",
    "````````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to Run the Code\n",
    "\n",
    "You can execute the code using the \"Run\" button at the top of this page and selecting \"Run on Binder\". You can make changes and save your own version of the notebooks to [Jovian](https://jovian.ai) by executing the following code cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jovian --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"omrahulpandey/scraping-yify-movies-lists\" on https://jovian.ai\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ai/omrahulpandey/scraping-yify-movies-lists\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ai/omrahulpandey/scraping-yify-movies-lists'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute this to save new versions of the notebook\n",
    "jovian.commit(project=\"scraping-yify-movies-lists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the webpage using the `requests`\n",
    "\n",
    "We'll use the `requests` library to download the web page.\n",
    "\n",
    "The library can be installed using `pip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import `requests` library\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library is now installed and imported.\n",
    "\n",
    "To download a web page, we'll use the `get` function from `requests`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The url of the website that needs to be scrapped needs to be stored in a varibale (in our case, say site_url)\n",
    "site_url = 'https://yts.rs/browse-movies'\n",
    "\n",
    "#requests.get() allows the webpage to be downloaded in the mentioned (site_url) variable.\n",
    "response = requests.get(site_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`requests.get` returns a response object containing the data from the web page and some other informations.\n",
    "\n",
    "The `.status_code` property can be used to check if the request was successful. A successful response will have the [HTTP status code](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status#successful_responses) between 200 to 299."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The request was successful! We can get the contents of the page using `response.text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_contents = response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the number of characters on the downloaded page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110008"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(page_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The page contains over 110,000 characters!\n",
    "\n",
    "Here are the first 600 characters of the page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html><html><head><script type=\"application/ld+json\">\\n            {\\n                \"@context\": \"https://schema.org\",\\n                \"@type\": \"Organization\",\\n                \"url\": \"https://yts.rs\",\\n                \"logo\": \"/images/og_yts_logo.png\"\\n            }</script><script async=\"\" src=\"https://www.googletagmanager.com/gtag/js?id=G-H6FV1F987B\"></script><script>\\n                                window.dataLayer = window.dataLayer || [];\\n                                function gtag(){dataLayer.push(arguments);}\\n                                gtag(\\'js\\', new Date());\\n              '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_contents[:600]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The characters presented above are nothing but part of the [HTML source code](https://en.wikipedia.org/wiki/HTML) of the web page. \n",
    "\n",
    "We can also save the `page_contents` to a file and view the page locally within Jupyter using \"File>Open\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('yify_webpage.html', 'w') as f:\n",
    "    f.write(page_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The page preview looks similar to the original page, but none of the links work. It must be noted that on a web page, new stuff are always expected to be added, so the preview may not exactly be the same as this but similar will do.\n",
    "\n",
    "![page_contents](https://i.imgur.com/g9b3vMs.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfuly downloaded the web page using `requests`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse the HTML source code using BeautifulSoup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install beautifulsoup4 --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc  = BeautifulSoup(page_contents, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Search and Browse YIFY Movies Torrent Downloads - YTS</title>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.find('title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<img alt=\"logo\" class=\"header__logo-image\" src=\"/images/logo-YTS.svg\"/>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.find('img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`doc.find('title')` and `doc.find('img')` gets the `title` and `img` tags along with its contents.\n",
    "\n",
    "\n",
    "Let us now define a function `get_doc(url)` to create a BeautifulSoup `doc` and return it, for each url received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc(url):\n",
    "    \"\"\"Download a web page and return a beautiful soup doc\"\"\"\n",
    "    # Download the page\n",
    "    response = requests.get(url)\n",
    "    # Check if download was successful\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(url))\n",
    "    # Create a bs4 doc    \n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = get_doc(site_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Search and Browse YIFY Movies Torrent Downloads - YTS</title>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.find('title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the function `get_doc` to download any web page and create a BeautifulSoup `doc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Searching \"tags\" containing movie data\n",
    "\n",
    "We'll inspect the [tags](https://www.w3schools.com/TAGS/default.ASP) within source code to find and get the following data:\n",
    "- Movie\n",
    "- Year\n",
    "- Genre\n",
    "- Rating\n",
    "- Url\n",
    "- Synopsis\n",
    "- Downloads\n",
    "\n",
    "![inspect_page](https://i.imgur.com/pWvMqnN.jpg)\n",
    "\n",
    "Right-Click on the part of the web page you wish to inspect.\n",
    "\n",
    "As it can be seen, `<a>` tag contains title of the movie.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Finding the title of the movie from the <a> tag\"\"\"\n",
    "\n",
    "movie_title_tags = doc.find_all('a', class_ ='text--bold palewhite title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gunda'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_title_tags[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movie title is successfully extracted! \n",
    "\n",
    "\n",
    "\n",
    "Lets define a function `get_movie_titles` to get a list of movie titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_titles(doc):\n",
    "    # get all the <a> tags with a unique class\n",
    "    movie_title_tags = doc.find_all('a', class_ ='text--bold palewhite title')\n",
    "    # create an empty list\n",
    "    movie_titles = []\n",
    "    for tag in movie_title_tags:\n",
    "    # for 'title' in each <tag> append it to the list\n",
    "        movie_titles.append(tag.text)\n",
    "    # return list    \n",
    "    return movie_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_movie_titles()` function successfully returns a list of movie tiltes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Finding the Year from <span> tag inside the <a> tag \"\"\"\n",
    "\n",
    "movie_year_tags = doc.find_all('span', class_ = 'text--gray year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_year_tags[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movie Year released is successfully extracted!\n",
    "\n",
    "Let's now define a function `get_movie_years` to get a list of years for movies released."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_years(doc):\n",
    "    # get all the <sapn> tags with a unique class\n",
    "    movie_year_tags = doc.find_all('span', class_ = 'text--gray year')\n",
    "    # create an empty list\n",
    "    movie_years =[]\n",
    "    for tag in movie_year_tags:\n",
    "    # for year in each <tag> append it to the list.    \n",
    "        movie_years.append(tag.text)\n",
    "    return movie_years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_movie_years()` sucessfully returns a list of movie years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Finding movie genre from <h4> tag that has a unique class genre \"\"\"\n",
    "\n",
    "genre_tags = doc.find_all('h4', class_ = 'genre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Documentary'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_tags[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movie Genre sucessfully extracted!\n",
    "\n",
    "\n",
    "Lets now define a function `get_movie_genres` to get a list of movie genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_genres(doc):\n",
    "    # get all the <h4> tags with unique a class\n",
    "    genre_tags = doc.find_all('h4', class_ = 'genre')\n",
    "    # create an empty list\n",
    "    movie_genres = []\n",
    "    for tag in genre_tags:\n",
    "    # for genre in each <tag> append it to the list.    \n",
    "        movie_genres.append(tag.text)\n",
    "    return movie_genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_movie_genres()` function successfully retunrs a list of movie genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Finding movie rating from <h4> tag that has a unique class rating \"\"\"\n",
    "\n",
    "rating_tags = doc.find_all('h4', class_ = 'rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7.4 / 10'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_tags[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movie rating is sucessfully extraced!\n",
    "\n",
    "Lets now define a function `get_movie_ratings` to get a list of movie ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_ratings(doc):\n",
    "    # get all the <h4> tags with a unique class\n",
    "    rating_tags= doc.find_all('h4', class_ = 'rating')\n",
    "    # create an empty list\n",
    "    movie_ratings = []\n",
    "    for tag in rating_tags:\n",
    "    # for rating in each <tag> append it to the list.    \n",
    "        movie_ratings.append(tag.text)\n",
    "    return movie_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_movie_ratings()` function successfuly returns a list of movie ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Finding movie url from <a> tag that has a unique `class text--bold palewhite title` \"\"\"\n",
    "\n",
    "movie_url_tags = doc.find_all('a', class_ ='text--bold palewhite title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/movie/gunda-2020'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_url_tags[0]['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The url is successfully extracted!\n",
    "\n",
    "However the url extracted here is only partial, to get the full url, we need to add base url to the url extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://yts.rs/movie/gunda-2020\n"
     ]
    }
   ],
   "source": [
    "movie0_url = 'https://yts.rs' + movie_url_tags[0]['href']\n",
    "print(movie0_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now successfully extracted full url of the movie.\n",
    "\n",
    "\n",
    "Lets now define a function `get_movie_urls` to get a list of full urls for each movie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_urls(doc):\n",
    "    # get all the <a> tags with a unique class\n",
    "    movie_url_tags = doc.find_all('a', class_ ='text--bold palewhite title')\n",
    "    # create an empty list\n",
    "    movie_urls = []\n",
    "    # the base url for the website\n",
    "    base_url = 'https://yts.rs'\n",
    "    for tag in movie_url_tags:\n",
    "    # for url in each tag, append it to the list after adding the base_url with url from each tag   \n",
    "        movie_urls.append(base_url + tag['href'])\n",
    "    return movie_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_movie_urls()` function successfully returns a list of movie urls.\n",
    "\n",
    "\n",
    "Similarily, we define functions `get_synopsis` and `get_downloaded` to get a list of movie synopsis and number of downloads information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synopsis(doc):\n",
    "    # create an empty list\n",
    "    synopses =[]\n",
    "    # get all the movie urls from the page\n",
    "    urls = get_movie_urls(doc)\n",
    "    for url in urls:\n",
    "        # for each url (page) get the beautiful soup doc object\n",
    "        movie_doc = get_doc(url)\n",
    "        # get all the <div> tags with a unique class\n",
    "        div_tag = movie_doc.find_all('div', class_ = 'synopsis col-sm-10 col-md-13 col-lg-12')\n",
    "        # get all the <p> tags inside the first <div> tag\n",
    "        p_tags = div_tag[0].find_all('p')\n",
    "        # the text (i,e the synopsis) part from the <p> tag is extracted using .text feature\n",
    "        synopsis = p_tags[0].text\n",
    "        # the synopsis is appended to the list synopses\n",
    "        synopses.append(synopsis)\n",
    "    return synopses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re to perform regular expression operations\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_downloaded(doc):\n",
    "    # create an empty list\n",
    "    downloadeds = []\n",
    "    # get all the movie urls on page\n",
    "    urls = get_movie_urls(doc)\n",
    "    for url in urls:\n",
    "        # for each url(page) create a beautiful soup doc object\n",
    "        movie_doc = get_doc(url)\n",
    "        # get all the <div> tags with unique class\n",
    "        div_tag = movie_doc.find_all('div', class_ = 'synopsis col-sm-10 col-md-13 col-lg-12')\n",
    "        # get all the <p> tags inside the first <div> tag\n",
    "        p_tags = div_tag[0].find_all('p')\n",
    "        # get all the <em> tags inside the second <p> tag\n",
    "        em_tag = p_tags[1].find_all('em')\n",
    "        # extarct the text from the <em> tag using .text\n",
    "        download = em_tag[0].text\n",
    "        # using reular expressions to strip of alphabets from the text using .compile()\n",
    "        regex = re.compile('[^0-9]')\n",
    "        downloaded = regex.sub('',download)\n",
    "        # append the integer to the list downloadeds\n",
    "        downloadeds.append(downloaded)\n",
    "    return downloadeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_synopsis()` and `get_downloaded()` successfully returns a list of `synopses` and `downloadeds` for each movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now define a function `scrap_page` to get a lsit of detials such as `movies`, `years`, `genres`, `ratings`, `urls`, `synopses` and `downloadeds` from a web page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_page(url):\n",
    "    # get beautiful soup doc object for url\n",
    "    doc = get_doc(url)\n",
    "    # create 7 empty lists for each field\n",
    "    movies,years,genres,ratings,urls,synopses,downloadeds=[],[],[],[],[],[],[]\n",
    "    \n",
    "    # get list of movie titles\n",
    "    movies = get_movie_titles(doc)\n",
    "    # get list of years\n",
    "    years = get_movie_years(doc)\n",
    "    # get list of genres\n",
    "    genres = get_movie_genres(doc)\n",
    "    # get list of ratings\n",
    "    ratings = get_movie_ratings(doc)\n",
    "    # get list of urls\n",
    "    urls = get_movie_urls(doc)\n",
    "    # get list of synopsis\n",
    "    synopses = get_synopsis(doc)\n",
    "    # get list of downloads\n",
    "    downloadeds = get_downloaded(doc)\n",
    "    \n",
    "    return movies,years,genres,ratings,urls,synopses,downloadeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `scrap_page()` function successfully returns a list of `movies`, `years`, `genres`, `ratings`. `urls`, `synopses` and `downloadeds` for a web page.\n",
    "\n",
    "\n",
    "\n",
    "Let us now define a function `website_scrap` to get all the information required from multiple pages and create a dictionary `movies_dict` for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def website_scrap():\n",
    "    # create 7 empty list for each field to append the corrsponding field list being returned\n",
    "    all_movies,all_years,all_genres,all_ratings,all_urls,all_synopses,all_downloadeds = [],[],[],[],[],[],[]\n",
    "    for i in range(1,21):\n",
    "        url = 'https://yts.rs/browse-movies?page={}'.format(i)\n",
    "        # get lists of movie filed details and append them to the final list\n",
    "        movies,years,genres,ratings,urls,synopses,downloadeds = scrap_page(url)\n",
    "        all_movies += movies\n",
    "        all_years += years\n",
    "        all_genres += genres\n",
    "        all_ratings += ratings\n",
    "        all_urls += urls\n",
    "        all_synopses += synopses\n",
    "        all_downloadeds += downloadeds\n",
    "        \n",
    "    # create a dictionary from the final list attained for each 'key' as movie detail    \n",
    "    movies_dict = {\n",
    "        'Movie': all_movies,\n",
    "        'Year': all_years,\n",
    "        'Genre': all_genres,\n",
    "        'Rating': all_ratings,\n",
    "        'Url': all_urls,\n",
    "        'Synopsis': all_synopses,\n",
    "        'Downloads': all_downloadeds\n",
    "    }   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above `website_scrap()` function gets list of details (`movies`, `years`, `genres`, `ratings`, `urls`, `synopses` and `downloadeds`) from multiple pages, adds it to a corresponding larger list (`all_movies`, `all_years`, `all_genres`, `all_ratings`, `all_urls`, `all_synopses`, and `all_downloadeds`) and returns it. ``.\n",
    "\n",
    "A dictionary `movie_dict` is created using returned lists. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining all of them together into a single cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def get_movie_titles(doc):\n",
    "    movie_title_tags = doc.find_all('a', class_ ='text--bold palewhite title')\n",
    "    movie_titles = []\n",
    "    for tag in movie_title_tags:\n",
    "        movie_titles.append(tag.text)\n",
    "    return movie_titles\n",
    "\n",
    "\n",
    "def get_movie_years(doc):\n",
    "    movie_year_tags = doc.find_all('span', class_ = 'text--gray year')\n",
    "    movie_years =[]\n",
    "    for tag in movie_year_tags:\n",
    "        movie_years.append(tag.text)\n",
    "    return movie_years\n",
    "\n",
    "\n",
    "def get_movie_genres(doc):\n",
    "    genre_tags = doc.find_all('h4', class_ = 'genre')\n",
    "    movie_genres = []\n",
    "    for tag in genre_tags:\n",
    "        movie_genres.append(tag.text)\n",
    "    return movie_genres\n",
    "\n",
    "\n",
    "def get_movie_ratings(doc):\n",
    "    rating_tags= doc.find_all('h4', class_ = 'rating')\n",
    "    movie_ratings = []\n",
    "    for tag in rating_tags:\n",
    "        movie_ratings.append(tag.text)\n",
    "    return movie_ratings\n",
    "\n",
    "\n",
    "def get_movie_urls(doc):\n",
    "    movie_url_tags = doc.find_all('a', class_ ='text--bold palewhite title')\n",
    "    movie_urls = []\n",
    "    base_url = 'https://yts.rs'\n",
    "    for tag in movie_url_tags:\n",
    "        movie_urls.append(base_url + tag['href'])\n",
    "    return movie_urls    \n",
    "    \n",
    "\n",
    "\n",
    "def get_synopsis(doc):\n",
    "    synopses =[]\n",
    "    urls = get_movie_urls(doc)\n",
    "    for url in urls:\n",
    "        movie_doc = get_doc(url)\n",
    "        div_tag = movie_doc.find_all('div', class_ = 'synopsis col-sm-10 col-md-13 col-lg-12')\n",
    "        p_tags = div_tag[0].find_all('p')\n",
    "        synopsis = p_tags[0].text\n",
    "        synopses.append(synopsis)\n",
    "    return synopses      \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def get_downloaded(doc):\n",
    "    downloadeds = []\n",
    "    urls = get_movie_urls(doc)\n",
    "    for url in urls:\n",
    "        movie_doc = get_doc(url)\n",
    "        div_tag = movie_doc.find_all('div', class_ = 'synopsis col-sm-10 col-md-13 col-lg-12')\n",
    "        p_tags = div_tag[0].find_all('p')\n",
    "        em_tag = p_tags[1].find_all('em')\n",
    "        download = em_tag[0].text\n",
    "        regex = re.compile('[^0-9]')\n",
    "        downloaded = regex.sub('',download)\n",
    "        downloadeds.append(downloaded)\n",
    "    return downloadeds\n",
    "    \n",
    "    \n",
    "def get_doc(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(url))\n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    return doc\n",
    "\n",
    "\n",
    "    \n",
    "def scrap_page(url):\n",
    "    doc = get_doc(url)\n",
    "    movies,years,genres,ratings,urls,synopses,downloadeds=[],[],[],[],[],[],[]\n",
    "    \n",
    "    movies = get_movie_titles(doc)\n",
    "    years = get_movie_years(doc)\n",
    "    genres = get_movie_genres(doc)\n",
    "    ratings = get_movie_ratings(doc)\n",
    "    urls = get_movie_urls(doc)\n",
    "    synopses = get_synopsis(doc)\n",
    "    downloadeds = get_downloaded(doc)\n",
    "    \n",
    "    return movies,years,genres,ratings,urls,synopses,downloadeds\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "def website_scrap():\n",
    "    all_movies,all_years,all_genres,all_ratings,all_urls,all_synopses,all_downloadeds = [],[],[],[],[],[],[]\n",
    "    for i in range(1,21):\n",
    "        url = 'https://yts.rs/browse-movies?page={}'.format(i)\n",
    "        movies,years,genres,ratings,urls,synopses,downloadeds = scrap_page(url)\n",
    "        all_movies += movies\n",
    "        all_years += years\n",
    "        all_genres += genres\n",
    "        all_ratings += ratings\n",
    "        all_urls += urls\n",
    "        all_synopses += synopses\n",
    "        all_downloadeds += downloadeds\n",
    "        \n",
    "    movies_dict = {\n",
    "        'Movie': all_movies,\n",
    "        'Year': all_years,\n",
    "        'Genre': all_genres,\n",
    "        'Rating': all_ratings,\n",
    "        'Url': all_urls,\n",
    "        'Synopsis': all_synopses,\n",
    "        'Downloads': all_downloadeds\n",
    "    }\n",
    "    \n",
    "    movies_df = pd.DataFrame(movies_dict, index = None) # Creates a dataframe from the dictionary and saves it to 'movies_df'\n",
    "    movies_df.to_csv('movies_data.csv') # Converts the Dataframe file 'movies_df' to a csv file and saves it in .csv format\n",
    "    return movies_df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Url</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Downloads</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gunda</td>\n",
       "      <td>2020</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>7.4 / 10</td>\n",
       "      <td>https://yts.rs/movie/gunda-2020</td>\n",
       "      <td>Documentary looks at the daily life of a pig ...</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bright: Samurai Soul</td>\n",
       "      <td>2021</td>\n",
       "      <td>ActionAdventure</td>\n",
       "      <td>5.6 / 10</td>\n",
       "      <td>https://yts.rs/movie/bright-samurai-soul-2021</td>\n",
       "      <td>Set in Japan during the end of the Shogunate ...</td>\n",
       "      <td>2323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It Boy</td>\n",
       "      <td>2013</td>\n",
       "      <td>ComedyRomance</td>\n",
       "      <td>6.4 / 10</td>\n",
       "      <td>https://yts.rs/movie/it-boy-2013</td>\n",
       "      <td>The thirty-eight year-old ambitious and worka...</td>\n",
       "      <td>3434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Bingo Long Traveling All-Stars &amp; Motor Kings</td>\n",
       "      <td>1976</td>\n",
       "      <td>ComedySport</td>\n",
       "      <td>6.8 / 10</td>\n",
       "      <td>https://yts.rs/movie/the-bingo-long-traveling-...</td>\n",
       "      <td>Tired of being treated like a slave by team o...</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Merry Heirs</td>\n",
       "      <td>1933</td>\n",
       "      <td>ComedyRomance</td>\n",
       "      <td>6.1 / 10</td>\n",
       "      <td>https://yts.rs/movie/the-merry-heirs-1933</td>\n",
       "      <td>A young salesman may inherit a wine-estate on...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Lift</td>\n",
       "      <td>2021</td>\n",
       "      <td>DramaHorror</td>\n",
       "      <td>7.5 / 10</td>\n",
       "      <td>https://yts.rs/movie/lift-2021</td>\n",
       "      <td>A usual working day turns unusual for Guru an...</td>\n",
       "      <td>24139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>2 or 3 Things I Know About Her</td>\n",
       "      <td>1967</td>\n",
       "      <td>ComedyDrama</td>\n",
       "      <td>6.8 / 10</td>\n",
       "      <td>https://yts.rs/movie/2-or-3-things-i-know-abou...</td>\n",
       "      <td>In this film, 'Her' refers to both Paris, the...</td>\n",
       "      <td>3838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>Under Wraps</td>\n",
       "      <td>2021</td>\n",
       "      <td>FamilyFantasy</td>\n",
       "      <td>4.7 / 10</td>\n",
       "      <td>https://yts.rs/movie/under-wraps-2021</td>\n",
       "      <td>Friends Marshall, Gilbert, and Amy accidental...</td>\n",
       "      <td>34239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>None's A Ton: A Turkuaz Live Concert Film</td>\n",
       "      <td>2020</td>\n",
       "      <td>Music</td>\n",
       "      <td>0 / 10</td>\n",
       "      <td>https://yts.rs/movie/nones-a-ton-a-turkuaz-liv...</td>\n",
       "      <td>A live concert film from Brooklyn-based power...</td>\n",
       "      <td>3939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>Rise and Shine, Benedict Stone</td>\n",
       "      <td>2021</td>\n",
       "      <td>Drama</td>\n",
       "      <td>7.1 / 10</td>\n",
       "      <td>https://yts.rs/movie/rise-and-shine-benedict-s...</td>\n",
       "      <td>Having lived in his family home on an island ...</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Movie  Year            Genre  \\\n",
       "0                                               Gunda  2020      Documentary   \n",
       "1                                Bright: Samurai Soul  2021  ActionAdventure   \n",
       "2                                              It Boy  2013    ComedyRomance   \n",
       "3    The Bingo Long Traveling All-Stars & Motor Kings  1976      ComedySport   \n",
       "4                                     The Merry Heirs  1933    ComedyRomance   \n",
       "..                                                ...   ...              ...   \n",
       "395                                              Lift  2021      DramaHorror   \n",
       "396                    2 or 3 Things I Know About Her  1967      ComedyDrama   \n",
       "397                                       Under Wraps  2021    FamilyFantasy   \n",
       "398         None's A Ton: A Turkuaz Live Concert Film  2020            Music   \n",
       "399                    Rise and Shine, Benedict Stone  2021            Drama   \n",
       "\n",
       "       Rating                                                Url  \\\n",
       "0    7.4 / 10                    https://yts.rs/movie/gunda-2020   \n",
       "1    5.6 / 10      https://yts.rs/movie/bright-samurai-soul-2021   \n",
       "2    6.4 / 10                   https://yts.rs/movie/it-boy-2013   \n",
       "3    6.8 / 10  https://yts.rs/movie/the-bingo-long-traveling-...   \n",
       "4    6.1 / 10          https://yts.rs/movie/the-merry-heirs-1933   \n",
       "..        ...                                                ...   \n",
       "395  7.5 / 10                     https://yts.rs/movie/lift-2021   \n",
       "396  6.8 / 10  https://yts.rs/movie/2-or-3-things-i-know-abou...   \n",
       "397  4.7 / 10              https://yts.rs/movie/under-wraps-2021   \n",
       "398    0 / 10  https://yts.rs/movie/nones-a-ton-a-turkuaz-liv...   \n",
       "399  7.1 / 10  https://yts.rs/movie/rise-and-shine-benedict-s...   \n",
       "\n",
       "                                              Synopsis Downloads  \n",
       "0     Documentary looks at the daily life of a pig ...       202  \n",
       "1     Set in Japan during the end of the Shogunate ...      2323  \n",
       "2     The thirty-eight year-old ambitious and worka...      3434  \n",
       "3     Tired of being treated like a slave by team o...       202  \n",
       "4     A young salesman may inherit a wine-estate on...       101  \n",
       "..                                                 ...       ...  \n",
       "395   A usual working day turns unusual for Guru an...     24139  \n",
       "396   In this film, 'Her' refers to both Paris, the...      3838  \n",
       "397   Friends Marshall, Gilbert, and Amy accidental...     34239  \n",
       "398   A live concert film from Brooklyn-based power...      3939  \n",
       "399   Having lived in his family home on an island ...      9999  \n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_scrap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "Here's what we have done so far:\n",
    "\n",
    "1. Downloaded a web page using `requests.get()` and the url of the web page.\n",
    "2. Parsed the HTML source code of the page using BeautifulSoup and created an object `doc` of type beautiful soup.\n",
    "3. Defined a function to create `doc` object for each url page.\n",
    "4. Defined functions to extract movie details such as `movies`, `years`, `genres`, `ratings`, `urls`, `synopses` and `downloadeds` from each page.\n",
    "5. Compiled the extracted information into Python lists and dictionaries.\n",
    "6. Created a pandas Dataframe oject to show the information extracted in tabular form.\n",
    "7. Convert and Save the Dataframe into a file of .csv format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. From the data collected in .csv file, perform some data analysis to get some insights on the data and visualizations.\n",
    "2. Maybe scrap an E-commerce or stocks prices websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
